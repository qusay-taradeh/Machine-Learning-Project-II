# Machine Learning Project II  
KNN, Logistic Regression, SVM, and Ensemble Methods Evaluation for Classification

## Summary  
Implementation of a machine learning project that explores and compares multiple classification algorithms, including K-Nearest Neighbors (KNN), Logistic Regression, Support Vector Machines (SVM) with various kernels, and ensemble methods such as Boosting (AdaBoost) and Bagging (Random Forest). The project uses a publicly available dataset and evaluates model performance using classification metrics like accuracy, precision, recall, F1-score, and ROC-AUC.

## Specifications  
This application should be able to perform the following tasks:
1. **Dataset Preparation:**  
   - Use a public dataset (e.g., Iris, Breast Cancer) with at least two classes.
   - Preprocess the data using Python libraries (NumPy, Pandas) for cleaning and splitting the data.

2. **K-Nearest Neighbors (KNN):**  
   - Implement KNN using APIs, experimenting with at least three distance metrics (Euclidean, Manhattan, Cosine).  
   - Use cross-validation to determine the optimal number of neighbors (K).  
   - Analyze and compare the impact of different distance metrics on model performance.

3. **Logistic Regression:**  
   - Train a Logistic Regression model and experiment with different regularization techniques (L1 and L2).  
   - Evaluate the model's performance using classification metrics and compare it with KNN.

4. **Support Vector Machines (SVM):**  
   - Implement SVM using Python APIs and train the model with at least three kernels (linear, polynomial, and RBF).  
   - Compare the performance of different kernels and discuss their impact on accuracy and other evaluation metrics.

5. **Ensemble Methods:**  
   - Boosting: Train a model using AdaBoost.  
   - Bagging: Train a model using Bagging or Random Forest.  
   - Compare the performance of Boosting and Bagging methods and discuss which ensemble method performs better relative to the individual models (KNN, Logistic Regression, SVM).

6. **Evaluation Metrics & Visualization:**  
   - Evaluate each model using accuracy, precision, recall, F1-score, and ROC-AUC.  
   - Use Matplotlib to visualize the evaluation metrics and performance comparisons.

## Authors
Qusay Taradeh, Ali Khalil
